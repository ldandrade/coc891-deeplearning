{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP para classificação\n",
    "\n",
    "Este notebook apesenta a contrução de uma Rede Neural de MLP para resolver o problema de classificação de vestuário. A base de dados utilizando encontra-se disponível no site https://github.com/zalandoresearch/fashion-mnist. Esta base de dados consiste de 70000 imagens as quais podem ser classificadas nas seguintes classes: \n",
    "\n",
    "*\tT-shirt/top\n",
    "*\tTrouser\n",
    "*\tPullover\n",
    "*\tDress\n",
    "*\tCoat\n",
    "*\tSandal\n",
    "*\tShirt\n",
    "*   Sneaker\n",
    "*\tBag\n",
    "*\tAnkle boot\n",
    "\n",
    "Alguns exemplos das imagens contidas nesta base de dados são apresentados a seguir:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](fashion-mnist-sprite.png \"Exemplos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento dos pacotes a serem utilizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:39:59.148135Z",
     "start_time": "2020-10-23T17:39:59.126196Z"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Helper libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carregamento do dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:01.271290Z",
     "start_time": "2020-10-23T17:40:00.881337Z"
    }
   },
   "outputs": [],
   "source": [
    "fashion_mnist = keras.datasets.fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:03.060409Z",
     "start_time": "2020-10-23T17:40:03.056435Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"numero de amostras de treinamento\", len(train_images))\n",
    "print(\"numero de amostras de teste\", len(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:05.663328Z",
     "start_time": "2020-10-23T17:40:05.657343Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Dimensões dos dados de entrada\", train_images.shape)\n",
    "print(\"Dimensões dos dados do target\", train_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:11.648364Z",
     "start_time": "2020-10-23T17:40:10.632082Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i]])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existem diversas ferramentas de visualização de dados multidimensionais, entre elas destaca-se a tecnica t-SNET (https://distill.pub/2016/misread-tsne/). Um exemplo de visualização empregando a base de dados descrita neste notebook é apresentado a seguir.  \n",
    "![alt text](embedding_fashion_mnist.gif \"Title\")\n",
    "\n",
    "Exemplo online http://projector.tensorflow.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:17.776714Z",
     "start_time": "2020-10-23T17:40:17.695904Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Maximo e Minimo do conjunto de treinamento\", np.max(train_images), np.min(train_images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessamento\n",
    "\n",
    "Na caixa de codigo anterior foi visto que as imagens de entrada da rede estão na escala de 0 a 255. Na proxima caixa voce implementara a padronização destas imagens no range de 0-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:40:24.056042Z",
     "start_time": "2020-10-23T17:40:23.801040Z"
    }
   },
   "outputs": [],
   "source": [
    "train_images = train_images / 255.0\n",
    "\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definição do modelo\n",
    "\n",
    "Na proxima caixa de texto voce implementara um modelo de rede neural MLP de duas camadas com 128 e 10 neuronios respetivamente. Experimente variar o numero de neuronios e de camadas. Nas camadas intermediarias (keras.layers.Dense) use qualquer função de ativação não linear (ex: relu(tf.nn.relu)) e na camada de saida use a ativação softmax(tf.nn.softmax)) \n",
    "\n",
    "Já que estamos usando uma rede totalmente conectada, lembre-se que para conseguir usar as imagens como entrada do modelo é necessário vetorizar as imagens (keras.layers.Flatten)\n",
    "\n",
    "Dica: Procure a documentação das funções citadas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28,28)),\n",
    "    keras.layers.Dense(128, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compile o modelo (https://www.tensorflow.org/api_docs/python/tf/keras/Model#compile)\n",
    "\n",
    "Para preparar o modelo é necessário mais algumas configurações.\n",
    "\n",
    "loss - Função custo a ser otimizado Ex: entropia cruzada, mse.\n",
    "\n",
    "optimizer - Otimizador selecionado Ex: adam, sgd. \n",
    "\n",
    "metrics - Métricas a serem avaliadas. Ex: Acurácia, F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinamento da rede neural: (https://www.tensorflow.org/api_docs/python/tf/keras/Model#fit)\n",
    "\n",
    "Vamos adicionar algumas funcionalidades ao nosso treinamento. Usaremos a técnica de parada precose e usaremos o método de salvar o modelo do tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-23T17:59:35.818889Z",
     "start_time": "2020-10-23T17:59:35.813902Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "earlyStopping = EarlyStopping(monitor='val_loss', patience=10, verbose=0, mode='min')\n",
    "mcp_save = ModelCheckpoint('fashion_mlp_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "# reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=7, verbose=1, epsilon=1e-4, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.5255 - accuracy: 0.8153 - val_loss: 0.4268 - val_accuracy: 0.8449\n",
      "Epoch 2/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.3875 - accuracy: 0.8602 - val_loss: 0.3904 - val_accuracy: 0.8606\n",
      "Epoch 3/20\n",
      "1200/1200 [==============================] - 10s 9ms/step - loss: 0.3480 - accuracy: 0.8728 - val_loss: 0.3639 - val_accuracy: 0.8752\n",
      "Epoch 4/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.3227 - accuracy: 0.8828 - val_loss: 0.3504 - val_accuracy: 0.8733\n",
      "Epoch 5/20\n",
      "1200/1200 [==============================] - 8s 7ms/step - loss: 0.3021 - accuracy: 0.8889 - val_loss: 0.3610 - val_accuracy: 0.8684\n",
      "Epoch 6/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.2862 - accuracy: 0.8940 - val_loss: 0.3405 - val_accuracy: 0.8824\n",
      "Epoch 7/20\n",
      "1200/1200 [==============================] - 8s 6ms/step - loss: 0.2771 - accuracy: 0.8981 - val_loss: 0.3162 - val_accuracy: 0.8890\n",
      "Epoch 8/20\n",
      "1200/1200 [==============================] - 7s 6ms/step - loss: 0.2655 - accuracy: 0.9010 - val_loss: 0.3130 - val_accuracy: 0.8901\n",
      "Epoch 9/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2532 - accuracy: 0.9066 - val_loss: 0.3278 - val_accuracy: 0.8844\n",
      "Epoch 10/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.2453 - accuracy: 0.9079 - val_loss: 0.3335 - val_accuracy: 0.8823\n",
      "Epoch 11/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2374 - accuracy: 0.9118 - val_loss: 0.3322 - val_accuracy: 0.8872\n",
      "Epoch 12/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2284 - accuracy: 0.9147 - val_loss: 0.3344 - val_accuracy: 0.8869\n",
      "Epoch 13/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2224 - accuracy: 0.9169 - val_loss: 0.3157 - val_accuracy: 0.8918\n",
      "Epoch 14/20\n",
      "1200/1200 [==============================] - 6s 5ms/step - loss: 0.2155 - accuracy: 0.9197 - val_loss: 0.3314 - val_accuracy: 0.8853\n",
      "Epoch 15/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.2081 - accuracy: 0.9227 - val_loss: 0.3199 - val_accuracy: 0.8914\n",
      "Epoch 16/20\n",
      "1200/1200 [==============================] - 9s 8ms/step - loss: 0.1998 - accuracy: 0.9248 - val_loss: 0.3223 - val_accuracy: 0.8908\n",
      "Epoch 17/20\n",
      "1200/1200 [==============================] - 9s 7ms/step - loss: 0.1931 - accuracy: 0.9268 - val_loss: 0.3345 - val_accuracy: 0.8878\n",
      "Epoch 18/20\n",
      "1200/1200 [==============================] - 10s 8ms/step - loss: 0.1898 - accuracy: 0.9297 - val_loss: 0.3315 - val_accuracy: 0.8932\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, batch_size=40, epochs=20, \n",
    "                    validation_split=0.2, verbose=True, callbacks=[earlyStopping, mcp_save])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot historico do treinamento e validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(..., ...)\n",
    "\n",
    "print('Test accuracy:', test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions\n",
    "With the model trained, we can use it to make predictions about some images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_selected = 300\n",
    "predicted_label = np.argmax(predictions[image_selected])\n",
    "true_label = test_labels[image_selected]\n",
    "predictions_array = predictions[image_selected]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(test_images[predicted_label], cmap=\"gray\")\n",
    "if predicted_label == true_label:\n",
    "    color = 'blue'\n",
    "else:\n",
    "    color = 'red'\n",
    "plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                100*np.max(predictions_array),\n",
    "                                class_names[true_label]),\n",
    "                                color=color)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}